{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code to generate test_protein_interactions.csv\n",
    "# test_raw = pd.read_csv('./test.csv', header=None, \n",
    "#                         keep_default_na=True, na_values='?',\n",
    "#                         na_filter=True)\n",
    "# field_desc = pd.read_csv('./field_descriptions.txt', header=None, delimiter='\\n')\n",
    "# test_interactions = test_raw[list(range(459, 2945))]\n",
    "# interaction_desc = []\n",
    "# for i in field_desc.iloc[list(range(459, 2945))][0]:\n",
    "#     interaction_desc.append(i[0 : 27].split(' ')[-1])\n",
    "# test_protein_interactions = []\n",
    "# for row in test_interactions.T:\n",
    "#     for col in test_interactions:\n",
    "#         p_type = test_interactions.loc[row, col]\n",
    "#         if (col % 2 == 1) and p_type != 'No':\n",
    "#             protein1 = test_raw.iloc[row, 0]\n",
    "#             protein2 = interaction_desc[col - 460]\n",
    "#             correlation = test_interactions.loc[row, col + 1]\n",
    "#             record = [protein1, protein2, p_type, correlation]\n",
    "#             test_protein_interactions.append(record)       \n",
    "# test_protein_interactions_df = pd.DataFrame(test_protein_interactions, columns=['protein1', 'protein2', 'type', 'correlation'])\n",
    "# test_protein_interactions_df.to_csv('./test_protein_interactions.csv', na_rep = '?', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(path, mode = \"train\"):\n",
    "    raw_data = pd.read_csv(path, header=None, \n",
    "                        keep_default_na=True, na_values='?',\n",
    "                        na_filter=True)\n",
    "    # 460th to 2945th columns are encoded in protein_interactions.csv\n",
    "    protein_interactions_cols = list(range(459, 2945))\n",
    "    \n",
    "    reduced_data = raw_data.drop(raw_data.columns[protein_interactions_cols], axis = 1)\n",
    "    reduced_data = reduced_data.T.reset_index(drop=True).T\n",
    "\n",
    "    cleaned_data = reduced_data\n",
    "    cleaned_rows, cleaned_columns = cleaned_data.shape\n",
    "    rename_dict = {0 : \"protein\", 1 : \"essential\", 444 : \"chromosome\",\n",
    "                   cleaned_columns - 1 : \"label\", cleaned_columns - 2 : \"localization\"}\n",
    "    if (mode != 'train'):\n",
    "        rename_dict = {0 : \"protein\", 1 : \"essential\", 444 : \"chromosome\",\n",
    "                        cleaned_columns - 1 : \"localization\"}\n",
    "    cleaned_data = cleaned_data.rename(rename_dict, axis = 1)\n",
    "    # 444 to 457 are continuous variables\n",
    "    for i in range(444, 458):\n",
    "        name = i + 1\n",
    "        cleaned_data[name] = pd.Series(cleaned_data[name], dtype = float)\n",
    "    if (mode == 'train'):\n",
    "        X = cleaned_data.drop([\"label\", \"protein\"], axis=1)  \n",
    "        Y = cleaned_data[\"label\"]\n",
    "    else:\n",
    "        X = cleaned_data.drop([\"protein\"], axis=1) \n",
    "        Y = None\n",
    "    X = X.apply(lambda c : pd.Series(LabelEncoder().fit_transform(c[c.notnull()]) if c.dtype != float else c , index=c[c.notnull()].index))\n",
    "    X[\"protein\"] = cleaned_data[\"protein\"]\n",
    "    X = X.drop(list(range(458, X.shape[1] - 1)), axis=1)\n",
    "    X = X.drop('localization', axis=1)\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = prep_data(\"./train.csv\", mode = 'train')\n",
    "test_X = prep_data(\"./test.csv\", mode = 'test')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     366\n",
       "1     192\n",
       "2      69\n",
       "3      58\n",
       "5      43\n",
       "4      43\n",
       "6      35\n",
       "7      18\n",
       "8      17\n",
       "9      10\n",
       "10      4\n",
       "11      3\n",
       "12      2\n",
       "14      1\n",
       "13      1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_indices = [item for item in list(range(0, train_X.shape[1] - 1)) if item not in range(444, 458)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "import sys\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "\n",
    "from missingpy import MissForest\n",
    "imputer = MissForest()\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(train_X.drop([\"protein\"], axis=1), cat_vars=categorical_indices))\n",
    "train_X[\"essential\"] = X_imputed[0].astype(int)\n",
    "train_X[\"chromosome\"] = X_imputed[444].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study potential relationship in protein_interactions\n",
    "protein_interactions = pd.read_csv('./protein_interactions.csv', header=None, na_values = '?.',\n",
    "                                   names = ('protein1', 'protein2', 'type', 'correlation'),\n",
    "                                  dtype = {'correlation' : str})\n",
    "# Trim the dot at the end of correlation and convert it to float\n",
    "protein_interactions['correlation'] = protein_interactions['correlation'].apply(\n",
    "                            lambda x : float(x[:-1]) \n",
    "                                       if str(x)[-1] == '.' \n",
    "                                        else float(x))\n",
    "\n",
    "test_protein_interactions = pd.read_csv('./test_protein_interactions.csv', na_values = '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein1, protein2 interaction is not communitive\n",
    "# display(protein_interactions.loc[protein_interactions.protein1 == \"P239467\"])\n",
    "# display(protein_interactions.loc[protein_interactions.protein2 == \"P239467\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: incorporate the protein_interaction relation back to the dataframe\n",
    "train_X['label'] = train_Y\n",
    "def join_protein_interaction(df, protein_interaction):\n",
    "    pro1_train = pd.merge(df, protein_interaction, left_on = 'protein', right_on = 'protein1', how='left')\n",
    "    pro2_train = train_X[['protein', 'essential', 'chromosome']]\n",
    "    protein_train = pd.merge(pro1_train, pro2_train, \n",
    "                         left_on = 'protein2', right_on = 'protein', how = 'left',\n",
    "                         suffixes = ['', '_interact'])\n",
    "    return protein_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join protein_interactions\n",
    "train_X_inter = join_protein_interaction(train_X, protein_interactions)\n",
    "test_X_inter = join_protein_interaction(test_X, test_protein_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein2 can be in train or test data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "X_train = train_X_inter.drop([\"label\", \"protein\", \"protein1\", \"protein2\", \"protein_interact\"], axis=1)\n",
    "X_train[\"type\"] = LabelEncoder().fit_transform(X_train[\"type\"]).astype(int)\n",
    "X_train[\"correlation\"] = X_train[\"correlation\"].fillna(0)\n",
    "Y_train = LabelEncoder().fit_transform(train_X_inter[\"label\"]).astype(int)\n",
    "X_test = test_X_inter.drop([\"protein\", \"protein1\", \"protein2\", \"protein_interact\"], axis=1)\n",
    "X_test[\"type\"] = LabelEncoder().fit_transform(X_test[\"type\"]).astype(int)\n",
    "X_test[\"correlation\"] = X_test[\"correlation\"].fillna(0)\n",
    "categorical_indices = [item for item in list(range(0, X_train.shape[1])) if item not in range(444, 458) and item != X_train.columns.get_loc(\"correlation\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['data_t'] = 'train'\n",
    "X_test['data_t'] = 'test'\n",
    "train_test_X = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n"
     ]
    }
   ],
   "source": [
    "train_test_X_imputed = pd.DataFrame(imputer.fit_transform(train_test_X.drop('data_t', axis=1), cat_vars=categorical_indices),\n",
    "                                   columns=train_test_X.drop('data_t', axis=1).columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_X_imputed['data_t'] = train_test_X['data_t'].values\n",
    "train_imputed = train_test_X_imputed[train_test_X_imputed['data_t'] == 'train'].drop('data_t', axis=1)\n",
    "test_imputed = train_test_X_imputed[train_test_X_imputed['data_t'] == 'test'].drop('data_t', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "clf = ExtraTreesClassifier(n_estimators=50)\n",
    "clf = clf.fit(train_imputed, Y_train)\n",
    "model = SelectFromModel(clf, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1312, 65)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selected = np.where(model.get_support())\n",
    "train_selected = pd.DataFrame(model.transform(train_imputed), columns=train_imputed.columns[feature_selected])\n",
    "test_selected = test_imputed.loc[:,train_imputed.columns[feature_selected]]\n",
    "train_selected['label'] = Y_train\n",
    "train_selected['protein'] = train_X_inter['protein'].values\n",
    "test_selected['protein'] = test_X_inter['protein'].values\n",
    "train_selected.shape\n",
    "# train_selected.to_csv('./train_selected.csv', index=False)\n",
    "# test_selected.to_csv('./test_selected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid = train_test_split(train_selected, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     471\n",
       "1     228\n",
       "3      85\n",
       "2      59\n",
       "6      55\n",
       "5      49\n",
       "4      43\n",
       "7      20\n",
       "8      18\n",
       "9      11\n",
       "10      5\n",
       "12      2\n",
       "11      2\n",
       "13      1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamyuan/miniconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "X_train_xg = train.drop(['label', 'protein'], axis=1)\n",
    "Y_train_xg = train['label']\n",
    "X_valid = valid.drop(['label', 'protein'], axis=1)\n",
    "Y_valid = valid['label']\n",
    "xg_reg = xgb.XGBClassifier(objective = 'multi:softprob', colsample_bytree = 0.3, learning_rate = 0.8,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10, num_class=15)\n",
    "xg_reg.fit(X_train_xg, Y_train_xg)\n",
    "valid_preds = xg_reg.predict(X_valid)\n",
    "test_preds = xg_reg.predict(test_selected.drop('protein', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6387832699619772"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(valid_preds == Y_valid).sum() / len(valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds_labeled = pd.DataFrame(valid_preds, columns = ['label'])\n",
    "valid_preds_labeled['protein'] = valid['protein'].values\n",
    "valid_preds_grouped = valid_preds_labeled.groupby('protein').agg(lambda x:x.value_counts().index[0])\n",
    "\n",
    "Y_valid_labeled = pd.DataFrame(Y_valid, columns = ['label'])\n",
    "Y_valid_labeled['protein'] = valid['protein'].values\n",
    "Y_valid_grouped = Y_valid_labeled.groupby('protein').agg(lambda x:x.value_counts().index[0])\n",
    "\n",
    "\n",
    "test_preds_labeled = pd.DataFrame(test_preds, columns = ['label'])\n",
    "test_preds_labeled['protein'] = test_selected['protein'].values\n",
    "test_preds_grouped = test_preds_labeled.groupby('protein').agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5956521739130435"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float((valid_preds_grouped == Y_valid_grouped).sum() / len(valid_preds_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.632546\n",
       "1    0.236220\n",
       "3    0.110236\n",
       "6    0.010499\n",
       "2    0.010499\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_grouped['label'].value_counts() / test_preds_grouped.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_grouped.index.name = 'Key'\n",
    "test_preds_grouped.columns = ['Label']\n",
    "test_preds_grouped.to_csv('./result_Mar22.csv', na_rep = '?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
